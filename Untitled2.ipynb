{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaLqKm3ylL480uYDHAlK8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Light896cart/GAN-mnist/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GVmmeDEIIU0f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "data_loader = DataLoader(mnist_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "e9Ba9-l4IZLV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim=100, num_classes=10):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim + num_classes, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh()  # Выходные значения в диапазоне [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        # Конкатенация латентного вектора и меток\n",
        "        input = torch.cat((z, labels), dim=1)\n",
        "        return self.model(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim=784, num_classes=10):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim + num_classes, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()  # Вероятность того, что изображение реальное\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # Конкатенация изображения и меток\n",
        "        input = torch.cat((x, labels), dim=1)\n",
        "        return self.model(input)\n"
      ],
      "metadata": {
        "id": "1zQl-dbKKcWd"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)"
      ],
      "metadata": {
        "id": "pXD0jRZUIylp"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for real_images, labels in data_loader:\n",
        "        real_images = real_images.view(-1, 784).to(device) # делаем из матрицы 28 на 28 вектор 784 и убираем канал RGB\n",
        "\n",
        "        # Создание one-hot кодов для меток\n",
        "        labels_one_hot = torch.zeros(real_images.size(0), 10).to(device) # создаем для каждого изображения в батче пустой вектор размерностью 10 заполненый нулями\n",
        "\n",
        "        labels_one_hot.scatter_(1, labels.view(-1, 1), 1) # scatter заполняет наш тензор первое значение ось ко которой мы будем выставлять значение\n",
        "        # Обучение дискриминатора\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Реальные изображения\n",
        "        labels_real = torch.ones(real_images.size(0), 1).to(device) # создаем метки изображений заполненные единицами\n",
        "        outputs_real = discriminator(real_images, labels_one_hot) # передаем наше изображение и метки, и получаем конкатезированный тензор\n",
        "        loss_real = criterion(outputs_real, labels_real) # дальше вычисляем функцию потерь\n",
        "\n",
        "        # Сгенерированные изображения\n",
        "        z = torch.randn(real_images.size(0), 100).to(device)  # создаем Латентное пространство\n",
        "        fake_labels = np.random.randint(0, 10, size=real_images.size(0))  # Случайные метки для генерации фейковых изображений\n",
        "        fake_labels_one_hot = torch.zeros(real_images.size(0), 10).to(device) # тензор заполненый нулями\n",
        "        fake_labels_one_hot.scatter_(1, torch.tensor(fake_labels).view(-1, 1).to(device), 1) # случайно проставляем метки\n",
        "\n",
        "        fake_images = generator(z, fake_labels_one_hot) # передаем в генератор латентное пространство и фейковые метки, то есть просто будем ожидать полученние из латентного пространство определенное число\n",
        "\n",
        "        labels_fake = torch.zeros(real_images.size(0), 1).to(device) # заполняем нуликами\n",
        "\n",
        "        outputs_fake = discriminator(fake_images.detach(), fake_labels_one_hot) # передаем фейковое изображение для того чтобы дескриптор угадал что это фейк\n",
        "\n",
        "        loss_fake = criterion(outputs_fake, labels_fake) # вычисляем потерю на сколько хорошо наш дескриптор угадал что изображение фейк\n",
        "\n",
        "        loss_D = loss_real + loss_fake # складываем наши веротяности\n",
        "        loss_D.backward() # проходимся обратным распространением\n",
        "        optimizer_D.step() # обновляем наши параметры дескриптора используя оптимизацию\n",
        "\n",
        "        # Обучение генератора\n",
        "        optimizer_G.zero_grad() # очищаем градиент\n",
        "\n",
        "        outputs_fake_for_G = discriminator(fake_images, fake_labels_one_hot) #\n",
        "        loss_G = criterion(outputs_fake_for_G, labels_real)\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step() # обновляем наши параметры генератора используя оптимизацию\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss D: {loss_D.item()}, Loss G: {loss_G.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EbTANekHJTnc",
        "outputId": "7e8be03c-5cc9-44c4-80d4-0e5b61f49261"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-9cc64fecda6d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# очищаем градиент\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutputs_fake_for_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels_one_hot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_fake_for_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-74a227f458db>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Конкатенация изображения и меток\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_digit(generator_model, digit_label):\n",
        "    generator_model.eval()   # Переводим модель в режим оценки\n",
        "\n",
        "    with torch.no_grad(): # убираем отслеживание градиента\n",
        "        z = torch.randn(1, 100).to(device)   # генериурем пространство(латентное)\n",
        "         # Создание one-hot кода для метки \"4\"\n",
        "        label_tensor = torch.zeros(1, 10).to(device) # создаем вектор\n",
        "\n",
        "        label_tensor[0][digit_label] = 1  # меняем 0 на 1 на позиции числа\n",
        "\n",
        "        generated_image = generator_model(z,label_tensor)  # используем генеративную модель и передаем туда латентное пространтсво и вектор меток\n",
        "\n",
        "        return generated_image.view(28 ,28).cpu().numpy() # получаем вектор размером 784 и разделяем его на матрицу 28 на 28\n",
        "\n",
        "# Генерация изображения цифры \"4\"\n",
        "generated_image_4 = generate_digit(generator , digit_label=2) # обращаемся к функции\n",
        "\n",
        "# Визуализация сгенерированного изображения (если используете matplotlib):\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(generated_image_4 ) # выводим массив ввиде изображения\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "zwWZbc6lQDp1",
        "outputId": "0b5bf222-0d40-4e9b-d309-e73c1c38af80"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем латентный вектор и метки как тензоры\n",
        "z = torch.tensor([0.5, -0.2]).unsqueeze(0)  # Добавляем размерность для батча\n",
        "labels = torch.tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]).unsqueeze(0)  # Добавляем размерность для батча\n",
        "\n",
        "# Конкатенация по оси колонок (dim=1)\n",
        "input_tensor = torch.cat((z, labels), dim=1)\n",
        "\n",
        "print(input_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMJ-nM2gRKC5",
        "outputId": "057b030b-b744-4173-d34d-f4063e1e6c08"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.5000, -0.2000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000,  0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor([2, 4, 5])\n",
        "print(labels.view(1, -1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QeQM8DtY48W",
        "outputId": "851648fe-a070-494d-ba96-05d3010c74e8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxJAckffcAM2"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}